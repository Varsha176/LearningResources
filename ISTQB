***************************************************************************** ISTQB Quick Bytes ****************************************************************************************

Absence-of-errors fallacy --If your software or system is unusable (or does not fulfill users' wishes) then it does not matter how many defects are found and fixed – it is still unusable.
tests wear out --f the same tests are repeated many times, they become increasingly ineffective at detecting new defects. To overcome this effect, existing tests and test data may need to be modified and new tests written.

whole team approach 
********************
the testers also work closely with developers and helps them to create the unit test cases. Testers help business representatives to create suitable acceptance tests.

Informal reviews --they are not documented.
Walkthrough: -- led by the authors/scribe,To achieve a common understanding and to gather feedback and To examine and discuss the validity of the proposed solutions.
Technical review: -- less formal review,led by the trained moderator but can also be led by a technical expert,Defects are found by the experts.
Inspection: -- most formal review type and led by the trained moderators.During inspection the documents are prepared and checked thoroughly by the reviewers before the meeting.
           -- It involves peers to examine the product

******************************
3-Points Estimating technique
*****************************
Two popular formulas:

1. Triangular distribution:

Triangular Distribution: E = (o + m + p ) / 3
2. Beta Distribution (PERT): E = (o + 4m + p ) / 6
where E is Estimate; o = optimistic estimate; p = pessimistic estimate; m = most likely estimate

************************************
Agile Testing Quadrants
************************************
Quadrant 1: Technology-facing tests that support the team
Quadrant 2: Business-facing tests that support the team
Quadrant 3: Business-facing tests that critique the product
Quadrant 4: Technology-facing tests that critique the product

 Usability testing is in Q3 (1 – C)
 Component testing is in Q1 (2 – A)
 Functional testing is in Q2 (3 – B)
 Reliability testing is in Q4 (4 – D)


What is risk likelihood?
Risk likelihood is the probability or frequency that a problem will occur, given the current conditions and assumptions. It can be measured in terms of percentage, ratio, frequency, or any other numerical scale. 
The higher the likelihood, the more likely the problem is.

Configuring test environments & Reporting on achieved coverage is mainly tester work.
In ATDD, tests are created, based on acceptance criteria to drive the development of the
related software.

**********************
shift left approach
*********************
 Early review is an example of the shift left approach.
TDD is an example of the shift left approach.
Early non-functional testing is an example of the shift left
approach.

************************** QA VS QC ***************************************
QC is a product-oriented, corrective approach that focuses on those activities supporting the achievement
of appropriate levels of quality. Testing is a major form of quality control, while others include formal
methods (model checking and proof of correctness), simulation and prototyping.

QA is a process-oriented, preventive approach that focuses on the implementation and improvement of
processes. It works on the basis that if a good process is followed correctly, then it will generate a good
product. QA applies to both the development and testing processes and is the responsibility of everyone
on a project.


************************** 7 Testing Principals ***************************************
1. Testing shows the presence, not the absence of defects. 
2. Exhaustive testing is impossible.
3. Early testing saves time and money.
4. Defects cluster together.
5. Tests wear out.
6. Testing is context-dependent. 
7. Absence-of-defects fallacy. 

****************************** Test Activities and Tasks ********************************
Test planning, Test monitoring and control.
Test analysis includes analyzing the test basis to identify testable features and to define and prioritize
associated test conditions, together with the related risks and risk levels.
Test design and test implementation -includes creating or acquiring the testware necessary for test execution,
Test execution, Test completion

******************************** SDLC Models ***********************************************
SDLC
models include: sequential development models (e.g., waterfall model, V-model), iterative development
models (e.g., spiral model, prototyping), and incremental development models (e.g., Unified Process).

TDD, ATDD and BDD are similar development approaches

************************************ Test Levels ***********************************************
Component testing/Unit Testing/Module Testing
Component Integration Testing/Unit Integration Testing -- testing between components within same module.
System testing 
System integration testing -testing of different modules.
Acceptance testing

Test levels are distinguished by the following non-exhaustive list of attributes, to avoid overlapping of test
activities:
• Test object
• Test objectives
• Test basis
• Defects and failures
• Approach and responsibilities

************************************ Test Types ***********************************************
Functional testing 
Non-functional testing 
Black-box testing
White-box testing 

**************************************** Diff between system testing and system integration testing ****************
System testing focuses on the overall behaviour and capabilities of an entire system or product.
System integration testing focuses on testing the interfaces of the system under test and other
systems and external services. For Example Zomato integration with google map. OPUS integration with oms billing system and integration with payment system.

System integration testing can be of three types:
1. Software-software : example amazon with payment gateways.
2. Software - hardware : Billing system with physical payment devices. Another example is embeded devices/IOT devices.
3. Hardware -hardware : Heavy machineries

**************************************************************************************
1) What is Test Basis?
The test basis is the information needed in order to start the test analysis and create our Test Cases.
https://tryqa.com/what-is-test-analysis-or-how-to-identify-the-test-conditions/

Possible Test Basis are:
________________________
System Requirement Document (SRS)
Functional Design Specification
Technical Design Specification
User Manual
Use Cases
Source Code
Business Requirement Document (BRD)

2) What are Test objects?
Test object in software testing is the application or the system being tested.

https://testsigma.com/blog/test-object/

3) TDD VS ATDD
TDD tests are focused on verifying the behaviour of individual units of code, while ATDD tests are focused on verifying that the software meets the needs and requirements of the users.
TDD written by devs while ATDD written by dev/qa/stakeholder.(Consider TDD at unit testing level and ATDD at system testing level like selenium code).

4) Acceptence testing (UAT) not only limited to functional testing but also covers operational testing(installation/uninstallation),
   Regulations, compliance etc.
Acceptence testing has 2 sub levels:
1. Alpha Testing -- done by internal users/stakeholders on preprod env.
2. Beta Testing -- performed by real users on real env to get feedback.Its a pre-release event.

****************************** Maintenance testing ***************************
1. Corrective
2. Adaptive
Scope depends on 3 factors
1. Degree of risk of the change.
2. Size of the existing System.
3. The size of the change.


Maintenance testing is required in case of update/upgrade/migration and retirement.

The update is a minor enhancement on the existing features while an upgrade is the addition of new features.


****************************** Reviews ******************************************
1. Informal review/Buddy Check --the objective is to detect anomalies.
2. Walkthrough -- led by the author, evaluate quality.
3. Technical Review -- is performed by technically qualified reviewers and led by a moderator. Known for peer reviews.
4. Inspection -- Most formal type of review. In inspections, the author cannot act as the review leader or scribe. Based on rules and checklist.

very imp point: The Evaluation of participants should never be the objective of a review.

******************************** Test Techniques *********************************
Black-box test techniques (also known as specification-based techniques) 
White-box test techniques (also known as structure-based techniques) 
Experience-based test techniques

1. Equivalence partitioning: Divides inputs into partitions/ranges/classes where all the elements of a particular range are expected to behave same.
    We take only 1 tc from each range. (<,1/0-range,>)
2. Boundry value analysis: 2 BVA => Left-1, Left, Right, Right+1
                           : 3 BVA =>Left-1,Left,Left+1,Right-1,Right,Right+1
3. Decision Table: Captures system req that contains logical conditions.
                 : The number of combinations will be 2 power N where N= number of conditions.


********************************** White box testing techniques ******************************
1. Statement testing --used to derive the minimum number of test cases to achieve 100% statement.
 very imp : Statement testing and statement coverage are not similar. Statement coverage is the measure to find out what coverage we have achieved.
           We use either statement testing or statement coverage. Don't use both together.

2. Branch Testing --derive the minimum number of tests to measure the branches in the fragment of the code.
   Branch coverage: is a metric to measure the coverage achieved by test sets.

100% branch coverage guarantees 100% statement coverage but not vice versa.

Branch coverage = Number of branches executed by the test
                 ________________________________________    * 100

                 Total number of branches in the code 

Error guessing is known as a fault attack.
Exploratory testing is sometimes conducted using session-based testing to structure the testing

statement cov = no of else +1


***************************** Test Estimation technique *********************************************
1. Estimation based on ratios: figures are collected from previous projects
within the organization, which makes it possible to derive “standard” ratios for similar projects

2. Extrapolation

3. Wideband Delphi: experts make experience-based estimations. Each expert, in isolation, estimates the effort. The results are collected and if there are deviations that are
out of range of the agreed-upon boundaries, the experts discuss their current estimates. Planning poker is a variant of this technique.

4. Three-point estimation: three estimations are made by the experts: the most optimistic estimation (a), the most likely estimation (m) and the most pessimistic estimation (b). The
final estimate (E) is their weighted arithmetic mean. In the most popular version of this technique, the
estimate is calculated as E = (a + 4*m + b) / 6. 

****************************** Test Case Prioritization ************************************************
1. Risk-based prioritization
2. Coverage-based prioritization
3. Requirements-based prioritization


Risk likelihood (>0 ,<1)

Testing quadrants
https://www.geeksforgeeks.org/agile-testing-quadrants/

************************************************************
What is the test condition?
A testable aspect of a component or system identified as basis of testing.
    Or
Test Condition in Software Testing is the specification that a tester must follow for testing a software application.


****************************************************************************
What is Test Charter?
documentation of test activities in session based explorartory testing.
****************************************************************************

What is test summary report?

Test summary report include Test Objective, Areas Covered/not covered, testing Approach, Platform Details ,Defect report,

*****************************************************************************
High Level Design -- system Tests
code stage - unit tests
Low level design -- Integration tests
Buisness req -Acceptence Tests

* Test case,Test data, test design all derived from specifications
* Req Analysis is not the phase of the fundamental test process.

Phase 1 – Test Planning and Control. ...
Phase 2 – Test Analysis and Design. ...
Phase 3 – Test Implementation and Execution. ...
Phase 4 – Evaluating Exit Criteria and Reporting. ...
Phase 5 – Test Closure.

Drivers are used in Bottom-Up Integration Testing.Drivers are known as Test harness and scaffolding.
Stubs used in the Top-down integration Testing

*Test specification creation is not the task of test lead/manager.
* Test case specification defines the expected results of test.
* a MAJOR task of test implementation and execution is Reporting discrepancies as incidents.
* What is the MAIN benefit of designing tests early in the life cycle? It helps prevent defects from being introduced into the code.
* What is the purpose of exit criteria? To define when a test level is complete.
* A defect arrival rate curve:Shows the number of newly discovered defects per unit time
* Contract and regulation testing is a part of Acceptance testing.
* A typical formal review process consists of six main steps: Planning • Kick-off • Preparation • Review meeting • Rework • Follow-up.
* Maintenance releases and technical assistance centers are example of external failure.
* Arc testing is known as branch testing.
* The _Equivalence partitioning____ technique can be used to achieve input and output coverage.
*  Majority of system errors occur in the requirement phase.
* A test procedure specification identifies all steps required to operate the system and exercise the specified test cases in order to implement the associated test design.
* System Integration testing should be done after unit testing.
* Verification Testing is known as Static Testing and it can be simply termed as checking whether we are developing the right product or not.
* Failure is _________ Incorrect program behaviour due to a fault in the program.
* Defect Management process does not include "Deliverable base-lining".
* Test matrix is a type of project status report.
* Peer Reviews are also called as : Technical Review
*  Compiling code is not a form of static analysis.
* Cost of the reviews will not include tool support.
* Deviation from expected result to actual result is failure.
* Functional testing is mostly Validation techniques.
* Reviewer should have technical and Business background.
*  Informal Review is inexpensive.
* Test procedure specification defines the sequence in which tests should be executed.

******************************************************************************************
*test closure activity includes --finalize and archiving, handover of testware. evaluate how testing went and analyse lessons.
*The test completion report is an output of the test completion activity.
*Test cases - output of test design activity.
*Documented sequences of test cases in execution order are the test procedures - output of test implementation activity.
*Test implementation produces the following outputs: test procedures (iv),automated test scripts, test suites, test data (ii), test execution schedule,
and test environment elements such as stubs, drivers, simulators, and service virtualizations.
** The test management role primarily involves activities related to test planning, test monitoring and control, and test completion. Thus,creating the test completion report, which is the prime output from the
test completion activity, is likely to be a task performed by the test management role.
**The whole team approach promotes robust communication and collaboration between the team members.
** Dynamic testing can identify some of the defects that can be found by static testing but not all of them.
** Testing quadrants have nothing to do with describing the relationships between test levels and Testing quadrants cannot help in assessing any type of coverage
* Testing quadrants is not a psychological model 
* Testing quadrants allow managers and other stakeholders to understand the relationships between test types, the activities they support (team support or product critique), and the viewpoint they are
focused on (business- or technology-facing).
** Risk level = Risk likelihood * Risk impact
Then, Risk impact = Risk level / Risk likelihood
*For every software development activity, there is a corresponding test activity
*The testing quadrants group test levels, test types, activities,test techniques and work products in Agile software development. In this model, tests can be business facing or technology facing.
* Risk monitoring is part of risk control, not risk analysis.
Risk identification itself does not allow us to implement risk mitigation activities. The mitigating actions are defined during the risk control phase


***********************************************************************************************************************************
A. Test analysis - prioritized test conditions (4) (e.g., acceptance criteria), and defect reports for defects identified in the test basis
B. Test design - prioritized test cases, test charters, coverage items (1), test data requirements, and test environment requirements
C. Test implementation - test procedures, automated test scripts, test suites, test data, test execution schedule (3), and test
environment elements such as stubs, drivers, simulators, and service virtualizations
D. Test completion - test completion report, documented lessons learned, action items for improvement, and change requests (2) (as product backlog items)









